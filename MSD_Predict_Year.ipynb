{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2026-01-07T02:25:43.489908Z","iopub.status.busy":"2026-01-07T02:25:43.489608Z"},"trusted":true,"id":"yOqPnCXswiTb"},"outputs":[],"source":["!pip install optuna imbalanced-learn\n","\n","# -------- core --------\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","# -------- optimization --------\n","import optuna\n","\n","# -------- sklearn: preprocessing & models --------\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.linear_model import LogisticRegression, Ridge\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.svm import LinearSVC, SVC\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# -------- sklearn: metrics & validation --------\n","from sklearn.metrics import (\n","    accuracy_score,\n","    balanced_accuracy_score,\n","    f1_score,\n","    confusion_matrix,\n","    classification_report\n",")\n","from sklearn.model_selection import StratifiedKFold, cross_validate\n","\n","# -------- imbalance handling --------\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.over_sampling import SMOTE\n","\n","# -------- XGBoost --------\n","from xgboost import XGBClassifier\n","\n","# -------- plotting --------\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","\n","# -------- misc --------\n","import os\n","from IPython.display import Image, display, Math, Markdown"]},{"cell_type":"markdown","metadata":{"id":"Fc6lki-lwiTd"},"source":["# Exploratory Data Analysis"]},{"cell_type":"markdown","metadata":{"id":"ziTCqIzywiTe"},"source":["#### Dataset retrieved from: Bertin-Mahieux, T. (2011). Year Prediction MSD [Dataset]. UCI Machine Learning Repository. https://doi.org/10.24432/C50K61."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"tDWkk2llwiTe"},"outputs":[],"source":["OUT_DIR = \"images_2\"\n","\n","path = \"YearPredictionMSD.txt\"\n","\n","n_features = 90\n","columns = [\"year\"] + [f\"audio_feature_{i}\" for i in range(1, n_features + 1)]\n","\n","df = pd.read_csv(\n","    path,\n","    header=None,\n","    names=columns\n",")\n","\n","df[\"decade\"] = (df[\"year\"] // 10) * 10\n","\n","feature_cols = [c for c in df.columns if c.startswith(\"audio_feature_\")]\n","df = df[[\"year\", \"decade\"] + feature_cols]\n","\n","display(df.columns)\n","display(df.head())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"MQi4TNxLwiTf"},"outputs":[],"source":["# let's see how features compare\n","df.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"cjTCcNLUwiTf"},"outputs":[],"source":["out = df.agg([\"count\", \"mean\", \"median\", \"std\", \"max\", \"min\"]).T\n","out[\"na\"] = df.isna().sum()\n","out.head(10)\n"]},{"cell_type":"markdown","metadata":{"id":"1fhbEQl2wiTf"},"source":["#### Fortunately, no NaN values. Clean dataset"]},{"cell_type":"markdown","metadata":{"id":"AH-wnTNwwiTg"},"source":["#### Let's start with examining the year and decade distribution to see if classes are equally represented"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"LEFXz8NZwiTg"},"outputs":[],"source":["print(f\"Number of distinct years in the dataset: {df.year.nunique()}\")\n","print(f\"Number of distinct decades in the dataset: {df.decade.nunique()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"SsoLR2hQwiTg"},"outputs":[],"source":["fig = go.Figure()\n","\n","fig.add_trace(go.Histogram(x=df[\"year\"], name=\"year\", opacity=0.6, nbinsx=100))\n","fig.add_trace(go.Histogram(x=df[\"decade\"], name=\"decade\", opacity=0.6, nbinsx=100))\n","fig.update_layout(barmode=\"overlay\",title=\"Distribution of Year and Decade\",xaxis_title=\"Year / Decade\",yaxis_title=\"Count\",legend_title=\"Variable\")\n","#fig.write_image(f\"{OUT_DIR}/song_count_by_year_and_decade.png\")\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"ovBcB2cFwiTg"},"outputs":[],"source":["decade_counts = df[\"decade\"].value_counts().sort_index()\n","decade_props = decade_counts / decade_counts.sum()\n","display(decade_counts)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"kkLGduB6wiTh"},"outputs":[],"source":["print(f\"Decade percentages, {decade_props}\")"]},{"cell_type":"markdown","metadata":{"id":"owvVqLqNwiTh"},"source":["### The decade labels in the dataset are strongly imbalanced, with approximately 60% of songs belonging to the 2000s, while earlier decades are substantially underrepresented. During modeling and evaluation, we will accordingly account for class imbalance by using evaluation metrics like macro-averaged F1 score and balanced accuracy and also by applying class weighting in the learning algorithms where supported. This ensures that our model is immune to discrimination between decades and the dominance of the majority class."]},{"cell_type":"markdown","metadata":{"id":"z34qSoXlwiTh"},"source":["## Audio Features\n","\n","### The individual features are not semantically labeled, but generally speaking, they capture global timbral and harmonic statistics sufficient for decade discrimination"]},{"cell_type":"markdown","metadata":{"id":"Q_PYPA0lwiTh"},"source":["### Are audio features numerically on the same scale??"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"_qz5DAAMwiTh"},"outputs":[],"source":["feature_cols = [c for c in df.columns if c.startswith(\"audio_feature_\")]\n","stds = df[feature_cols].std()\n","display(stds.describe())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"NjmgbA6kwiTh"},"outputs":[],"source":["# which features have the highest stds?\n","stds.sort_values(ascending=False).head(10)\n"]},{"cell_type":"markdown","metadata":{"id":"pn3GaQrVwiTh"},"source":["### They are not on the same scale. So we scale them."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"JTnJrhiRwiTh"},"outputs":[],"source":["scaler = StandardScaler()\n","df_scaled = df.copy()\n","df_scaled[feature_cols] = scaler.fit_transform(df[feature_cols])\n"]},{"cell_type":"markdown","metadata":{"id":"7edJLOm9wiTh"},"source":["### The heatmap below shows us that some audio features show gradual shifts across decades, suggesting systematic changes in music characteristics over time."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"DwonZo3TwiTh"},"outputs":[],"source":["df_agg = (df_scaled.groupby(\"decade\")[feature_cols].mean())\n","fig = px.imshow(df_agg,aspect=\"auto\",labels=dict(x=\"Audio feature index\",y=\"Decade\",color=\"Mean (z-scored)\"),title=\"Mean Z-Scored Audio Feature Values per Decade\")\n","#fig.write_image(f\"{OUT_DIR}/Audio_Fts_per_Decade.png\")\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"O7Kc-9TqwiTi"},"source":["### The trend line below shows decade-wise trends in the scaled audio features.\n","\n","### Earlier decades are characterized by substantial dispersion in feature values, with different features exhibiting markedly different average levels. As we move toward later decades, these feature trajectories progressively converge, resulting in a tighter clustering of values and reduced cross-feature variability. This suggests that songs from more recent decades share more homogeneous aggregate audio characteristics. Importantly, this convergence does not imply uniformity across features; several dimensions continue to exhibit distinct temporal trends. Rather, the figure indicates that temporal information is distributed across many features and manifests as gradual, systematic shifts rather than abrupt changes."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"QPrtDHAxwiTi"},"outputs":[],"source":["df_feat_trend = df_scaled.groupby(\"decade\")[feature_cols].mean().reset_index()\n","df_long = df_feat_trend.melt(\"decade\", feature_cols, \"feature\", \"value\")\n","\n","fig = px.line(df_long, x=\"decade\", y=\"value\", color=\"feature\",\n","        title=\"Decade-wise Trends of Scaled Audio Features\"\n",")\n","fig.update_layout(showlegend=False, yaxis_title=\"Mean scaled feature value\")\n","#fig.write_image(f\"{OUT_DIR}/Audio_Fts_TrendLine.png\")\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"LzzPUffUwiTi"},"outputs":[],"source":["\n","df_feat_trend = df.groupby(\"decade\")[feature_cols].mean().reset_index()\n","df_long = df_feat_trend.melt(\"decade\", feature_cols, \"feature\", \"value\")\n","\n","fig = px.line(df_long, x=\"decade\", y=\"value\", color=\"feature\",\n","        title=\"Decade-wise Trends of Audio Features\"\n",")\n","fig.update_layout(showlegend=False, yaxis_title=\"Feature value\")\n","# fig.write_image(\"song_count_by_year_and_decade.png\")\n","fig.show()\n"]},{"cell_type":"markdown","metadata":{"id":"tb_MnZbvwiTi"},"source":["### There are 90 audio features, but are they distinct? Or are some of them redundant? If redundancy exists, we can later utilise PCA to reduce the number of features."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"AbNqoAZmwiTi"},"outputs":[],"source":["corr = df_scaled[feature_cols].corr()\n","display(corr)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"urOGqEq6wiTi"},"outputs":[],"source":["fig = px.imshow(corr,aspect=\"auto\",color_continuous_scale=\"RdBu\",zmin=-1,zmax=1,title=\"Correlation Between Audio Features (Z-Scored)\", height=900, width=900)\n","#fig.write_image(f\"{OUT_DIR}/audio_fts_corr.png\")\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"hOd3BioWwiTi"},"outputs":[],"source":["upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n","prop_strong = (upper > 0.7).sum().sum() / upper.count().sum()\n","prop_strong"]},{"cell_type":"markdown","metadata":{"id":"AqyRBMQewiTi"},"source":["### Correlation analysis summary:\n","\n","### Pairwise correlations between features are generally low: only about 0.2% of all feature pairs have an absolute correlation above 0.7. This indicates that most audio features capture distinct information rather than being globally redundant. However, the correlation heatmap still reveals small, localized clusters of correlated features, suggesting limited and structured redundancy within specific feature groups rather than widespread overlap across the feature set."]},{"cell_type":"markdown","metadata":{"id":"__nmedoSwiTi"},"source":["# Machine Learning and Classification\n","\n","### Having characterized the data and its structure, we next establish a baseline decade-classification model to assess whether the audio features contain predictive temporal information."]},{"cell_type":"markdown","metadata":{"id":"TrAYS-3NwiTi"},"source":["## Baseline Model: Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"-qwnYPs9wiTi"},"source":["### We begin with a simple, class-weighted multinomial logistic regression as a baseline. This model provides a conservative reference point, allowing us to assess whether the audio features contain usable decade-level information before introducing more complex models."]},{"cell_type":"markdown","metadata":{"id":"3Nq-UJq2wiTi"},"source":["#### F1 vs. Accuracy\n","\n","##### Accuracy measures the overall proportion of correctly classified samples. However, in this task the decade classes are imbalanced, meaning some decades appear much more frequently than others. In such settings, a model can achieve high accuracy by favoring the dominant classes while performing poorly on under-represented ones.\n","\n","##### The macro-averaged F1 score addresses this issue by computing the F1 score independently for each decade and then averaging across decades. This gives equal importance to all classes, making the metric more sensitive to whether the model performs consistently across both frequent and rare decades.\n","\n","##### For this reason, we report both accuracy and macro F1: accuracy reflects overall correctness, while macro F1 better reflects balanced performance across decades.\n","\n","![image.png](attachment:image.png)\n","\n","![image-2.png](attachment:image-2.png)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMJ4V42WwiTj"},"outputs":[],"source":["from IPython.display import display, Math, Markdown\n","\n","display(Markdown(\"## Evaluation Metrics\"))\n","\n","display(Markdown(\n","\"**Accuracy** measures the overall fraction of correctly classified samples. \"\n","\"It is dominated by majority classes and can be misleading when class frequencies are highly imbalanced.\"\n","))\n","display(Math(r\"\\text{Accuracy}=\\frac{1}{N}\\sum_{i=1}^{N}\\mathbf{1}(\\hat{y}_i=y_i)\"))\n","\n","display(Markdown(\n","\"**Balanced Accuracy** compensates for class imbalance by averaging recall across classes. \"\n","\"Each class contributes equally, so rare classes influence the metric as much as frequent ones.\"\n","))\n","display(Math(r\"\\text{Balanced Accuracy}=\\frac{1}{K}\\sum_{k=1}^{K}\\frac{TP_k}{TP_k+FN_k}\"))\n","\n","display(Markdown(\n","\"**F1 score** measures the balance between precision (how many predicted positives are correct) \"\n","\"and recall (how many true positives are recovered). It penalizes both false positives and false negatives.\"\n","))\n","display(Math(r\"\\text{Precision}_k=\\frac{TP_k}{TP_k+FP_k}\"))\n","display(Math(r\"\\text{Recall}_k=\\frac{TP_k}{TP_k+FN_k}\"))\n","display(Math(r\"\\text{F1}_k=\\frac{2\\,\\text{Precision}_k\\,\\text{Recall}_k}{\\text{Precision}_k+\\text{Recall}_k}\"))\n","\n","display(Markdown(\n","\"**Macro-F1** averages the F1 score independently over all classes. \"\n","\"This treats every class equally and strongly penalizes models that perform well on dominant classes \"\n","\"but poorly on rare ones.\"\n","))\n","display(Math(r\"\\text{Macro-F1}=\\frac{1}{K}\\sum_{k=1}^{K}\\text{F1}_k\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"w3v5gVrYwiTj"},"outputs":[],"source":["target_ = \"decade\"\n","X = df[feature_cols]\n","y = df[target_]\n","\n","# official UCI split -- refer to citation\n","X_train = X.iloc[:463715].to_numpy(dtype=np.float32)\n","y_train = y.iloc[:463715].to_numpy(dtype=np.float32)\n","\n","X_test = X.iloc[463715:].to_numpy(dtype=np.float32)\n","y_test = y.iloc[463715:].to_numpy(dtype=np.float32)\n","labels = sorted(np.unique(y_test))"]},{"cell_type":"code","source":["len(X_train)"],"metadata":{"id":"WiD6eKtw4tj8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"u_vTUUg4wiTj"},"outputs":[],"source":["all_accuracies = []"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"H6ZvXXtswiTj"},"outputs":[],"source":["############### Initialize model ###############\n","pipe_lr=Pipeline([\n"," (\"scaler\",StandardScaler()),\n"," (\"classifier\",LogisticRegression(class_weight=\"balanced\",max_iter=2000,n_jobs=-1))\n","])\n","\n","############### Real model ###############\n","pipe_lr.fit(X_train,y_train)\n","y_pred=pipe_lr.predict(X_test)\n","\n","acc=accuracy_score(y_test,y_pred)\n","macro_f1=f1_score(y_test,y_pred,average=\"macro\")\n","bal_acc=balanced_accuracy_score(y_test,y_pred)\n","\n","############### Chance level (label shuffle) ###############\n","y_train_chance=np.random.permutation(y_train)\n","\n","pipe_lr.fit(X_train,y_train_chance)\n","y_pred_chance=pipe_lr.predict(X_test)\n","\n","acc_chance=accuracy_score(y_test,y_pred_chance)\n","macro_f1_chance=f1_score(y_test,y_pred_chance,average=\"macro\")\n","bal_acc_chance=balanced_accuracy_score(y_test,y_pred_chance)\n","\n","############### Print results ###############\n","print(\"Logistic Regression results\")\n","print(\"Accuracy (real):\",acc)\n","print(\"Balanced accuracy (real):\",bal_acc)\n","print(\"Macro F1 (real):\",macro_f1)\n","print()\n","print(\"Chance-level results (label shuffled)\")\n","print(\"Accuracy (chance):\",acc_chance)\n","print(\"Balanced accuracy (chance):\",bal_acc_chance)\n","print(\"Macro F1 (chance):\",macro_f1_chance)\n","\n","all_accuracies+=[\n"," {\"Model\":\"Logistic Regression\",\"Run\":\"True\",\n","  \"Accuracy\":acc,\"Balanced Accuracy\":bal_acc,\"Macro F1\":macro_f1},\n"," {\"Model\":\"Logistic Regression\",\"Run\":\"Chance\",\n","  \"Accuracy\":acc_chance,\"Balanced Accuracy\":bal_acc_chance,\"Macro F1\":macro_f1_chance}\n","]\n","\n","############### Confusion matrices ###############\n","cm_tr=confusion_matrix(y_test,y_pred,labels=labels,normalize=\"true\")\n","cm_ch=confusion_matrix(y_test,y_pred_chance,labels=labels,normalize=\"true\")\n","\n","fig=make_subplots(1,2,subplot_titles=[\"Real\",\"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_tr,2),texttemplate=\"%{text}\",showscale=True),1,1)\n","fig.add_trace(go.Heatmap(z=cm_ch,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_ch,2),texttemplate=\"%{text}\",showscale=True),1,2)\n","fig.update_layout(width=1500,height=800,\n","                  xaxis_title=\"Predicted decade\",\n","                  yaxis_title=\"True decade\")\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","#fig.write_image(f\"{OUT_DIR}/lr_tr_vs_chance.png\")\n"]},{"cell_type":"markdown","metadata":{"id":"7ObhQCSIwiTj"},"source":["### The baseline model performs above chance but remains very limited, indicating that decade-specific information is present but not linearly separable. This motivates the use of more expressive models in subsequent analyses."]},{"cell_type":"markdown","metadata":{"id":"u1LGCCX3wiTj"},"source":["## More advanced model: SVC (Linear)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"VPwkeIRIwiTn"},"outputs":[],"source":["############### Initialize model ###############\n","pipe_svc=Pipeline([\n"," (\"scaler\",StandardScaler()),\n"," (\"classifier\",LinearSVC(class_weight=\"balanced\",max_iter=5000))\n","])\n","\n","############### Real model ###############\n","pipe_svc.fit(X_train,y_train)\n","y_pred=pipe_svc.predict(X_test)\n","\n","acc=accuracy_score(y_test,y_pred)\n","macro_f1=f1_score(y_test,y_pred,average=\"macro\")\n","bal_acc=balanced_accuracy_score(y_test,y_pred)\n","\n","############### Chance level (label shuffle) ###############\n","y_train_chance=np.random.permutation(y_train)\n","\n","pipe_svc.fit(X_train,y_train_chance)\n","y_pred_chance=pipe_svc.predict(X_test)\n","\n","acc_chance=accuracy_score(y_test,y_pred_chance)\n","macro_f1_chance=f1_score(y_test,y_pred_chance,average=\"macro\")\n","bal_acc_chance=balanced_accuracy_score(y_test,y_pred_chance)\n","\n","############### Print results ###############\n","print(\"Linear SVM results\")\n","print(\"Accuracy (real):\",acc)\n","print(\"Balanced accuracy (real):\",bal_acc)\n","print(\"Macro F1 (real):\",macro_f1)\n","print()\n","print(\"Chance-level results (label shuffled)\")\n","print(\"Accuracy (chance):\",acc_chance)\n","print(\"Balanced accuracy (chance):\",bal_acc_chance)\n","print(\"Macro F1 (chance):\",macro_f1_chance)\n","\n","all_accuracies+=[\n"," {\"Model\":\"Linear SVM\",\"Run\":\"True\",\n","  \"Accuracy\":acc,\"Balanced Accuracy\":bal_acc,\"Macro F1\":macro_f1},\n"," {\"Model\":\"Linear SVM\",\"Run\":\"Chance\",\n","  \"Accuracy\":acc_chance,\"Balanced Accuracy\":bal_acc_chance,\"Macro F1\":macro_f1_chance}\n","]\n","\n","############### Confusion matrices ###############\n","cm_tr=confusion_matrix(y_test,y_pred,labels=labels,normalize=\"true\")\n","cm_ch=confusion_matrix(y_test,y_pred_chance,labels=labels,normalize=\"true\")\n","\n","fig=make_subplots(1,2,subplot_titles=[\"Real\",\"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_tr,2),texttemplate=\"%{text}\",showscale=True),1,1)\n","fig.add_trace(go.Heatmap(z=cm_ch,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_ch,2),texttemplate=\"%{text}\",showscale=True),1,2)\n","fig.update_layout(width=1500,height=800,\n","                  xaxis_title=\"Predicted decade\",\n","                  yaxis_title=\"True decade\")\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","#fig.write_image(f\"{OUT_DIR}/svm_tr_vs_chance.png\")\n"]},{"cell_type":"markdown","metadata":{"id":"xzBcATHKwiTn"},"source":["## SVC with RBF Kernel"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"XXoFKzBAwiTn"},"outputs":[],"source":["# ===================== Median-capped training set =====================\n","counts=pd.Series(y_train).value_counts()\n","cap=int(counts.quantile(0.50))\n","print(\"Original class counts:\")\n","print(counts.sort_index())\n","strategy={k:min(v,cap) for k,v in counts.to_dict().items()}\n","rus=RandomUnderSampler(sampling_strategy=strategy,random_state=0)\n","X_train_cap,y_train_cap=rus.fit_resample(X_train,y_train)\n","\n","print(\"\\nActual counts after resampling:\")\n","print(pd.Series(y_train_cap).value_counts().sort_index())\n","\n","# ===================== Pipeline =====================\n","pipe_svc=Pipeline([\n"," (\"scaler\",StandardScaler()),\n"," (\"classifier\",SVC(kernel=\"rbf\",class_weight=\"balanced\"))\n","])\n","\n","# ===================== Grid  =====================\n","param_grid={\n"," \"classifier__C\":[1,10,100],\n"," \"classifier__gamma\":[1e-4,1e-3,1e-2]\n","}\n","\n","grid=GridSearchCV(\n"," estimator=pipe_svc,\n"," param_grid=param_grid,\n"," scoring=\"balanced_accuracy\",\n"," cv=2,\n"," n_jobs=-1,\n"," verbose=2\n",")\n","\n","# ===================== Grid search =====================\n","grid.fit(X_train_cap,y_train_cap)\n","\n","print(\"Best params:\",grid.best_params_)\n","print(\"CV balanced accuracy:\",grid.best_score_)\n","\n","best_model=grid.best_estimator_\n","\n","# ===================== Real model =====================\n","best_model.fit(X_train_cap,y_train_cap)\n","y_pred=best_model.predict(X_test)\n","\n","acc=accuracy_score(y_test,y_pred)\n","macro_f1=f1_score(y_test,y_pred,average=\"macro\")\n","bal_acc=balanced_accuracy_score(y_test,y_pred)\n","\n","# ===================== Chance level =====================\n","y_train_chance=np.random.permutation(y_train_cap)\n","\n","best_model.fit(X_train_cap,y_train_chance)\n","y_pred_chance=best_model.predict(X_test)\n","\n","acc_chance=accuracy_score(y_test,y_pred_chance)\n","macro_f1_chance=f1_score(y_test,y_pred_chance,average=\"macro\")\n","bal_acc_chance=balanced_accuracy_score(y_test,y_pred_chance)\n","\n","# ===================== Log results =====================\n","all_accuracies+=[\n"," {\"Model\":\"RBF SVM\",\"Run\":\"True\",\n","  \"Accuracy\":acc,\"Balanced Accuracy\":bal_acc,\"Macro F1\":macro_f1},\n"," {\"Model\":\"RBF SVM\",\"Run\":\"Chance\",\n","  \"Accuracy\":acc_chance,\"Balanced Accuracy\":bal_acc_chance,\"Macro F1\":macro_f1_chance}\n","]\n","\n","# ===================== Confusion matrices =====================\n","labels=sorted(np.unique(y_test))\n","cm_tr=confusion_matrix(y_test,y_pred,labels=labels,normalize=\"true\")\n","cm_ch=confusion_matrix(y_test,y_pred_chance,labels=labels,normalize=\"true\")\n","\n","fig=make_subplots(1,2,subplot_titles=[\"Real\",\"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_tr,2),texttemplate=\"%{text}\",showscale=True),1,1)\n","fig.add_trace(go.Heatmap(z=cm_ch,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_ch,2),texttemplate=\"%{text}\",showscale=True),1,2)\n","fig.update_layout(width=1500,height=800,\n","                  xaxis_title=\"Predicted decade\",\n","                  yaxis_title=\"True decade\")\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","#fig.write_image(f\"{OUT_DIR}/svm_rbf_grid_tr_vs_chance.png\")\n"]},{"cell_type":"markdown","metadata":{"id":"tUC7pu8ewiTn"},"source":["### Decent performance but not much better than our baseline (logistic) model."]},{"cell_type":"markdown","metadata":{"id":"7GLXiGhbwiTn"},"source":["## On par with SVC: Linear Discriminant Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"FXpDmLDGwiTn"},"outputs":[],"source":["############### Initialize model ###############\n","pipe_lda=Pipeline([\n"," (\"scaler\",StandardScaler()),\n"," (\"classifier\",LinearDiscriminantAnalysis())\n","])\n","\n","############### Real model ###############\n","pipe_lda.fit(X_train,y_train)\n","y_pred=pipe_lda.predict(X_test)\n","\n","acc=accuracy_score(y_test,y_pred)\n","macro_f1=f1_score(y_test,y_pred,average=\"macro\")\n","bal_acc=balanced_accuracy_score(y_test,y_pred)\n","\n","############### Chance level (label shuffle) ###############\n","y_train_chance=np.random.permutation(y_train)\n","\n","pipe_lda.fit(X_train,y_train_chance)\n","y_pred_chance=pipe_lda.predict(X_test)\n","\n","acc_chance=accuracy_score(y_test,y_pred_chance)\n","macro_f1_chance=f1_score(y_test,y_pred_chance,average=\"macro\")\n","bal_acc_chance=balanced_accuracy_score(y_test,y_pred_chance)\n","\n","############### Print results ###############\n","print(\"LDA results\")\n","print(\"Accuracy (real):\",acc)\n","print(\"Balanced accuracy (real):\",bal_acc)\n","print(\"Macro F1 (real):\",macro_f1)\n","print()\n","print(\"Chance-level results (label shuffled)\")\n","print(\"Accuracy (chance):\",acc_chance)\n","print(\"Balanced accuracy (chance):\",bal_acc_chance)\n","print(\"Macro F1 (chance):\",macro_f1_chance)\n","\n","all_accuracies+=[\n"," {\"Model\":\"LDA\",\"Run\":\"True\",\n","  \"Accuracy\":acc,\"Balanced Accuracy\":bal_acc,\"Macro F1\":macro_f1},\n"," {\"Model\":\"LDA\",\"Run\":\"Chance\",\n","  \"Accuracy\":acc_chance,\"Balanced Accuracy\":bal_acc_chance,\"Macro F1\":macro_f1_chance}\n","]\n","\n","############### Confusion matrices ###############\n","labels=np.unique(y_test)\n","cm_tr=confusion_matrix(y_test,y_pred,labels=labels,normalize=\"true\")\n","cm_ch=confusion_matrix(y_test,y_pred_chance,labels=labels,normalize=\"true\")\n","\n","fig=make_subplots(1,2,subplot_titles=[\"Real\",\"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_tr,2),texttemplate=\"%{text}\",showscale=True),1,1)\n","fig.add_trace(go.Heatmap(z=cm_ch,x=labels,y=labels,colorscale=\"Blues\",\n","                         text=np.round(cm_ch,2),texttemplate=\"%{text}\",showscale=True),1,2)\n","fig.update_layout(width=1500,height=800,\n","                  xaxis_title=\"Predicted decade\",\n","                  yaxis_title=\"True decade\")\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","#fig.write_image(f\"{OUT_DIR}/lda_tr_vs_chance.png\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AKSiDt1TwiTo"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","############### Hyperparameter Optimization with Subset ###############\n","# Use subset for faster optimization\n","SUBSET_SIZE = 50000\n","np.random.seed(0)\n","subset_indices = np.random.choice(len(X_train), size=SUBSET_SIZE, replace=False)\n","X_subset = X_train[subset_indices]\n","y_subset = y_train[subset_indices]\n","\n","def objective_rf(trial):\n","    params = {\n","        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n","        'max_depth': trial.suggest_int('max_depth', 10, 40),\n","        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n","        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n","        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),\n","        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n","        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n","        'n_jobs': -1,\n","        'random_state': 0\n","    }\n","\n","    rf = RandomForestClassifier(**params)\n","\n","    # 3-fold CV on macro F1\n","    scores = cross_val_score(rf, X_subset, y_subset, cv=3, scoring='f1_macro', n_jobs=1)\n","\n","    return scores.mean()\n","\n","# Create and run study\n","print(\"Starting Random Forest hyperparameter optimization...\")\n","print(f\"Using subset of {SUBSET_SIZE} samples for faster tuning\")\n","\n","optuna_already_run=True\n","\n","if not optuna_already_run:\n","    study_rf=optuna.create_study(direction=\"maximize\", study_name='rf_msd')\n","    study_rf.optimize(objective_rf,n_trials=50, show_progress_bar=True)\n","    with open(\"study_rf.pkl\",\"wb\") as f:\n","        pickle.dump(study_rf,f)\n","else:\n","    with open(\"study_rf.pkl\",\"rb\") as f:\n","        study_rf=pickle.load(f)\n","\n","\n","\n","print(\"\\nBest parameters:\", study_rf.best_params)\n","print(\"Best macro F1 (on subset CV):\", study_rf.best_value)\n","\n","\n","\n","############### Initialize model ###############\n","best_params_rf = study_rf.best_params\n","best_params_rf.update({\n","    \"n_jobs\": -1,\n","    \"random_state\": 0\n","})\n","\n","rf = RandomForestClassifier(**best_params_rf)\n","\n","############### Real model (trained on FULL training set) ###############\n","print(\"\\nTraining on full training set...\")\n","rf.fit(X_train, y_train)\n","y_pred = rf.predict(X_test)\n","\n","acc = accuracy_score(y_test, y_pred)\n","macro_f1 = f1_score(y_test, y_pred, average=\"macro\")\n","bal_acc = balanced_accuracy_score(y_test, y_pred)\n","\n","############### Chance level ###############\n","print(\"Training chance model...\")\n","ytr_chance = np.random.permutation(y_train)\n","rf.fit(X_train, ytr_chance)\n","y_pred_chance = rf.predict(X_test)\n","\n","acc_chance = accuracy_score(y_test, y_pred_chance)\n","macro_f1_chance = f1_score(y_test, y_pred_chance, average=\"macro\")\n","bal_acc_chance = balanced_accuracy_score(y_test, y_pred_chance)\n","\n","############### Print results ###############\n","print(\"\\n\" + \"=\"*50)\n","print(\"RANDOM FOREST RESULTS\")\n","print(\"=\"*50)\n","print(\"Accuracy (real):\", acc)\n","print(\"Balanced accuracy (real):\", bal_acc)\n","print(\"Macro F1 (real):\", macro_f1)\n","print()\n","print(\"Accuracy (chance):\", acc_chance)\n","print(\"Balanced accuracy (chance):\", bal_acc_chance)\n","print(\"Macro F1 (chance):\", macro_f1_chance)\n","\n","all_accuracies += [\n","    {\"Model\": \"Random Forest\", \"Run\": \"True\", \"Accuracy\": acc, \"Balanced Accuracy\": bal_acc, \"Macro F1\": macro_f1},\n","    {\"Model\": \"Random Forest\", \"Run\": \"Chance\", \"Accuracy\": acc_chance, \"Balanced Accuracy\": bal_acc_chance, \"Macro F1\": macro_f1_chance}\n","]\n","\n","############### Confusion matrices ###############\n","labels = sorted(np.unique(y_test))\n","\n","cm_tr = confusion_matrix(y_test, y_pred, labels=labels, normalize=\"true\")\n","cm_ch = confusion_matrix(y_test, y_pred_chance, labels=labels, normalize=\"true\")\n","\n","fig = make_subplots(1, 2, subplot_titles=[\"Real\", \"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr, x=labels, y=labels, colorscale=\"Blues\",\n","                         text=np.round(cm_tr, 2), texttemplate=\"%{text}\", showscale=True), 1, 1)\n","fig.add_trace(go.Heatmap(z=cm_ch, x=labels, y=labels, colorscale=\"Blues\",\n","                         text=np.round(cm_ch, 2), texttemplate=\"%{text}\", showscale=True), 1, 2)\n","fig.update_layout(width=1500, height=800,\n","                  xaxis_title=\"Predicted decade\", yaxis_title=\"True decade\",\n","                  xaxis2_title=\"Predicted decade\")\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","\n","fig.write_image(f\"{OUT_DIR}/rf_tr_vs_chance.png\")\n","\n","############### Feature Importance ###############\n","# Train final model for feature importance\n","rf.fit(X_train, y_train)\n","feature_importance = rf.feature_importances_\n","\n","# Sort features by importance\n","importance_df = pd.DataFrame({\n","    'feature': feature_cols,\n","    'importance': feature_importance\n","}).sort_values('importance', ascending=False)\n","\n","print(\"\\nTop 10 Most Important Features:\")\n","print(importance_df.head(10))\n","\n","# Optional: Plot feature importance\n","fig_imp = go.Figure(go.Bar(\n","    x=importance_df['importance'].head(20),\n","    y=importance_df['feature'].head(20),\n","    orientation='h'\n","))\n","fig_imp.update_layout(\n","    title=\"Top 20 Feature Importances (Random Forest)\",\n","    xaxis_title=\"Importance\",\n","    yaxis_title=\"Feature\",\n","    height=600,\n","    yaxis={'categoryorder': 'total ascending'}\n",")\n","fig_imp.show()\n","#fig_imp.write_image(f\"{OUT_DIR}/rf_feature_importance.png\")"]},{"cell_type":"markdown","metadata":{"id":"xRGHks85wiTn"},"source":["### Given the poor accuracy results here, we will opt for a more advanced model: XGBoost."]},{"cell_type":"markdown","metadata":{"id":"VlAzRjxdwiTo"},"source":["## More advanced model: XGBoost\n","\n","### We next evaluate a gradient-boosted decision tree model (XGBoost), which is well suited to capturing nonlinear interactions in high-dimensional tabular audio features."]},{"cell_type":"markdown","metadata":{"id":"DDFwGErgwiTo"},"source":["### We initially ran a grid search to find the optimal parameters for classification. However, given how computationally expensive the search was, we stopped the kernel after 56 hours and opted for a more efficient library: Optuna. Grid search evaluates all combinations of parameters to evaluate which drives best classification results; however, Optuna consistenly evaluates combinations that are more likely to improve classification performance, thereby cutting down the amount of time needed to converge on an ideal combination."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"eCpTDDLHwiTo"},"outputs":[],"source":["# ---------------- CONFIG ----------------\n","USE_GPU=False\n","N_TRIALS=100\n","CV_FOLDS=5\n","N_CORES=8\n","# --------------------------------------\n","\n","# -------- XGBOOST DATA VIEW -----------\n","from sklearn.preprocessing import LabelEncoder\n","\n","le_xgb=LabelEncoder()\n","ytr_xgb=le_xgb.fit_transform(y_train)\n","yte_xgb=le_xgb.transform(y_test)\n","\n","Xtr_xgb=X_train\n","Xte_xgb=X_test\n","# --------------------------------------\n","\n","def objective(trial):\n","    params={\n","        \"n_estimators\":trial.suggest_int(\"n_estimators\",300,900),\n","        \"max_depth\":trial.suggest_int(\"max_depth\",3,7),\n","        \"learning_rate\":trial.suggest_float(\"learning_rate\",0.02,0.1,log=True),\n","        \"subsample\":trial.suggest_float(\"subsample\",0.6,0.9),\n","        \"colsample_bytree\":trial.suggest_float(\"colsample_bytree\",0.4,0.8),\n","        \"min_child_weight\":trial.suggest_int(\"min_child_weight\",1,10),\n","        \"reg_lambda\":trial.suggest_float(\"reg_lambda\",1.0,10.0),\n","        \"reg_alpha\":trial.suggest_float(\"reg_alpha\",0.0,1.0),\n","        \"objective\":\"multi:softprob\",\n","        \"eval_metric\":\"mlogloss\",\n","        \"n_jobs\":1,\n","        \"random_state\":0,\n","        \"tree_method\":\"gpu_hist\" if USE_GPU else \"hist\",\n","        \"device\":\"cuda\" if USE_GPU else None\n","    }\n","\n","    model=XGBClassifier(**params)\n","    cv=StratifiedKFold(n_splits=CV_FOLDS,shuffle=True,random_state=0)\n","\n","    scores=[]\n","    for tr,va in cv.split(Xtr_xgb,ytr_xgb):\n","        model.fit(Xtr_xgb[tr],ytr_xgb[tr])\n","        pred=model.predict(Xtr_xgb[va])\n","        scores.append(f1_score(ytr_xgb[va],pred,average=\"macro\"))\n","\n","    return np.mean(scores)\n","\n","optuna_already_run=True\n","\n","if not optuna_already_run:\n","    study=optuna.create_study(direction=\"maximize\")\n","    study.optimize(objective,n_trials=N_TRIALS,n_jobs=N_CORES)\n","    with open(\"study.pkl\",\"wb\") as f:\n","        pickle.dump(study,f)\n","else:\n","    with open(\"study.pkl\",\"rb\") as f:\n","        study=pickle.load(f)\n"]},{"cell_type":"markdown","metadata":{"id":"YL5MUCgiwiTo"},"source":["### Using the ideal parameters from the Optuna search, we are able to classify song decade based on audio features with 65% accuracy. Chance level is 10%."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"DoPmLCIowiTo"},"outputs":[],"source":["optuna.visualization.plot_optimization_history(study)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"BDXGgwwlwiTo"},"outputs":[],"source":["optuna.visualization.plot_param_importances(study)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"DY26Ex64wiTo"},"outputs":[],"source":["optuna.visualization.plot_slice(study)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"wGUFs6VBwiTo"},"outputs":[],"source":["############### Initialize model ###############\n","best_params = study.best_params\n","best_params.update({\n","    \"objective\": \"multi:softprob\",\n","    \"eval_metric\": \"mlogloss\",\n","    \"n_jobs\": -1,\n","    \"random_state\": 0,\n","    \"tree_method\": \"gpu_hist\" if USE_GPU else \"hist\",\n","    \"device\": \"cuda\" if USE_GPU else None\n","})\n","\n","xgb = XGBClassifier(**best_params)\n","\n","\n","\n","\n","############### Real model ###############\n","xgb.fit(Xtr_xgb, ytr_xgb)\n","y_pred = xgb.predict(Xte_xgb)\n","\n","acc = accuracy_score(yte_xgb,y_pred)\n","macro_f1 = f1_score(yte_xgb,y_pred,average=\"macro\")\n","bal_acc = balanced_accuracy_score(yte_xgb,y_pred)\n","############### Chance level ###############\n","ytr_chance = np.random.permutation(ytr_xgb)\n","xgb.fit(Xtr_xgb, ytr_chance)\n","y_pred_chance = xgb.predict(Xte_xgb)\n","\n","acc_chance = accuracy_score(yte_xgb,y_pred_chance)\n","macro_f1_chance = f1_score(yte_xgb,y_pred_chance,average=\"macro\")\n","bal_acc_chance = balanced_accuracy_score(yte_xgb,y_pred_chance)\n","############### Print results ###############\n","print(\"Accuracy (real):\",acc)\n","print(\"Balanced accuracy (real):\",bal_acc)\n","print(\"Macro F1 (real):\",macro_f1)\n","print()\n","print(\"Accuracy (chance):\",acc_chance)\n","print(\"Balanced accuracy (chance):\",bal_acc_chance)\n","print(\"Macro F1 (chance):\",macro_f1_chance)\n","\n","\n","all_accuracies += [\n","{\"Model\":\"XGBoost\",\"Run\":\"True\",\"Accuracy\":acc,\"Balanced Accuracy\":bal_acc,\"Macro F1\":macro_f1},\n","{\"Model\":\"XGBoost\",\"Run\":\"Chance\",\"Accuracy\":acc_chance,\"Balanced Accuracy\":bal_acc_chance,\"Macro F1\":macro_f1_chance}\n","\n","]\n","\n","############### Confusion matrices ###############\n","labels = np.arange(len(le_xgb.classes_))\n","\n","cm_tr = confusion_matrix(yte_xgb, y_pred, labels=labels, normalize=\"true\")\n","cm_ch = confusion_matrix(yte_xgb, y_pred_chance, labels=labels, normalize=\"true\")\n","\n","fig = make_subplots(1, 2, subplot_titles=[\"Real\", \"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr,x=labels,y=labels,colorscale=\"Blues\",text=np.round(cm_tr,2),texttemplate=\"%{text}\",showscale=True),1,1)\n","fig.add_trace(go.Heatmap(z=cm_ch,x=labels,y=labels,colorscale=\"Blues\",text=np.round(cm_ch,2),texttemplate=\"%{text}\",showscale=True),1,2)\n","fig.update_layout(width=1500, height=800,xaxis_title=\"Predicted class (ordinal index)\",yaxis_title=\"True class (ordinal index)\")\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","\n","#fig.write_image(f\"{OUT_DIR}/xgb_tr_vs_chance.png\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"7N_ifmV5wiTp"},"outputs":[],"source":["############### Initialize model ###############\n","counts=pd.Series(ytr_xgb).value_counts()\n","cap=int(counts.quantile(0.5))\n","strategy={k:min(v,cap) for k,v in counts.to_dict().items()}\n","rus=RandomUnderSampler(sampling_strategy=strategy,random_state=0)\n","Xtr_cap,ytr_cap=rus.fit_resample(Xtr_xgb,ytr_xgb)\n","\n","best_params=study.best_params\n","best_params.update({\n"," \"objective\":\"multi:softprob\",\"eval_metric\":\"mlogloss\",\n"," \"n_jobs\":-1,\"random_state\":0,\n"," \"tree_method\":\"gpu_hist\" if USE_GPU else \"hist\",\n"," \"device\":\"cuda\" if USE_GPU else None\n","})\n","\n","xgb=XGBClassifier(**best_params)\n","\n","############### Real model ###############\n","\n","xgb.fit(Xtr_cap,ytr_cap)\n","y_pred=xgb.predict(Xte_xgb)\n","\n","acc=accuracy_score(yte_xgb,y_pred)\n","macro_f1=f1_score(yte_xgb,y_pred,average=\"macro\")\n","bal_acc=balanced_accuracy_score(yte_xgb,y_pred)\n","\n","############### Chance level ###############\n","\n","ytr_cap_chance=np.random.permutation(ytr_cap)\n","\n","xgb.fit(Xtr_cap,ytr_cap_chance)\n","y_pred_chance=xgb.predict(Xte_xgb)\n","acc_chance=accuracy_score(yte_xgb,y_pred_chance)\n","macro_f1_chance=f1_score(yte_xgb,y_pred_chance,average=\"macro\")\n","bal_acc_chance=balanced_accuracy_score(yte_xgb,y_pred_chance)\n","############### Print results ###############\n","print(\"Accuracy (real):\",acc)\n","print(\"Balanced accuracy (real):\",bal_acc)\n","print(\"Macro F1 (real):\",macro_f1)\n","print()\n","print(\"Accuracy (chance):\",acc_chance)\n","print(\"Balanced accuracy (chance):\",bal_acc_chance)\n","print(\"Macro F1 (chance):\",macro_f1_chance)\n","\n","\n","all_accuracies+=[\n","{\"Model\":\"XGBoost (capped)\",\"Run\":\"True\",\"Accuracy\":acc,\"Balanced Accuracy\":bal_acc,\"Macro F1\":macro_f1},\n","{\"Model\":\"XGBoost (capped)\",\"Run\":\"Chance\",\"Accuracy\":acc_chance,\"Balanced Accuracy\":bal_acc_chance,\"Macro F1\":macro_f1_chance}\n","]\n","\n","############### Confusion matrices ###############\n","\n","labels=np.arange(len(le_xgb.classes_))\n","cm_tr=confusion_matrix(yte_xgb,y_pred,labels=labels,normalize=\"true\")\n","cm_ch=confusion_matrix(yte_xgb,y_pred_chance,labels=labels,normalize=\"true\")\n","\n","fig=make_subplots(1,2,subplot_titles=[\"Real\",\"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr,x=labels,y=labels,colorscale=\"Blues\",text=np.round(cm_tr,2),texttemplate=\"%{text}\",showscale=True),1,1)\n","fig.add_trace(go.Heatmap(z=cm_ch,x=labels,y=labels,colorscale=\"Blues\",text=np.round(cm_ch,2),texttemplate=\"%{text}\",showscale=True),1,2)\n","fig.update_layout(width=1500,height=800,\n","                  xaxis_title=\"Predicted class (ordinal index)\",\n","                  yaxis_title=\"True class (ordinal index)\")\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","\n","#fig.write_image(f\"{OUT_DIR}/xgb_capped_tr_vs_chance.png\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"86bfHCwywiTp"},"outputs":[],"source":["# ordinal encoding from reference labels\n","decades_sorted=np.sort(np.unique(y_train))\n","dec2i={d:i for i,d in enumerate(decades_sorted)}\n","\n","ytr_ord=np.array([dec2i[d] for d in y_train])\n","yte_ord=np.array([dec2i[d] for d in y_test])\n","\n","ord_model=Pipeline([\n"," (\"scaler\",StandardScaler()),\n"," (\"regressor\",Ridge(alpha=1.0))\n","])\n","\n","ord_model.fit(X_train,ytr_ord)\n","y_pred_cont=ord_model.predict(X_test)\n","y_pred=np.clip(np.rint(y_pred_cont),0,len(decades_sorted)-1).astype(int)\n","\n","acc=accuracy_score(yte_ord,y_pred)\n","macro_f1=f1_score(yte_ord,y_pred,average=\"macro\")\n","bal_acc=balanced_accuracy_score(yte_ord,y_pred)\n","\n","ytr_chance=np.random.permutation(ytr_ord)\n","ord_model.fit(X_train,ytr_chance)\n","y_pred_chance=np.clip(\n"," np.rint(ord_model.predict(X_test)),\n"," 0,len(decades_sorted)-1\n",").astype(int)\n","\n","acc_chance=accuracy_score(yte_ord,y_pred_chance)\n","macro_f1_chance=f1_score(yte_ord,y_pred_chance,average=\"macro\")\n","bal_acc_chance=balanced_accuracy_score(yte_ord,y_pred_chance)\n","\n","print(\"Accuracy (real):\",acc)\n","print(\"Balanced accuracy (real):\",bal_acc)\n","print(\"Macro F1 (real):\",macro_f1)\n","print()\n","print(\"Accuracy (chance):\",acc_chance)\n","print(\"Balanced accuracy (chance):\",bal_acc_chance)\n","print(\"Macro F1 (chance):\",macro_f1_chance)\n","\n","\n","\n","all_accuracies+=[\n","{\"Model\":\"Ordinal Ridge\",\"Run\":\"True\",\"Accuracy\":acc,\"Balanced Accuracy\":bal_acc,\"Macro F1\":macro_f1},\n","{\"Model\":\"Ordinal Ridge\",\"Run\":\"Chance\",\"Accuracy\":acc_chance,\"Balanced Accuracy\":bal_acc_chance,\"Macro F1\":macro_f1_chance}\n","]\n","\n","labels=np.arange(len(decades_sorted))\n","cm_tr=confusion_matrix(yte_ord,y_pred,labels=labels,normalize=\"true\")\n","cm_ch=confusion_matrix(yte_ord,y_pred_chance,labels=labels,normalize=\"true\")\n","\n","fig=make_subplots(1,2,subplot_titles=[\"Real\",\"Chance\"])\n","fig.add_trace(go.Heatmap(z=cm_tr,x=labels,y=labels,colorscale=\"Blues\",text=np.round(cm_tr,2),texttemplate=\"%{text}\",showscale=True),1,1)\n","fig.add_trace(go.Heatmap(z=cm_ch,x=labels,y=labels,colorscale=\"Blues\",text=np.round(cm_ch,2),texttemplate=\"%{text}\",showscale=True),1,2)\n","fig.update_yaxes(autorange=\"reversed\")\n","fig.show()\n","\n","#fig.write_image(f\"{OUT_DIR}/ordinal_ridge_tr_vs_chance.png\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"Q6tX7lIkwiTp"},"outputs":[],"source":["df=pd.DataFrame(all_accuracies)\n","df.to_csv(f\"{OUT_DIR}/all_model_results.csv\",index=False)"]},{"cell_type":"markdown","metadata":{"id":"IDX0zbNwwiTp"},"source":["# Conclusion"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DUiGcCSdwiTp"},"outputs":[],"source":["import plotly.graph_objects as go\n","import plotly.express as px\n","\n","METRICS=[\"Accuracy\",\"Balanced Accuracy\",\"Macro F1\"]\n","\n","# ---------- auto models ----------\n","models=sorted(df[\"Model\"].unique())\n","\n","# ---------- auto colors ----------\n","palette=px.colors.qualitative.Plotly\n","model_colors={m:palette[i%len(palette)] for i,m in enumerate(models)}\n","\n","def hex_to_rgba(hex_color,alpha):\n","    h=hex_color.lstrip(\"#\")\n","    r,g,b=(int(h[i:i+2],16) for i in (0,2,4))\n","    return f\"rgba({r},{g},{b},{alpha})\"\n","\n","for METRIC_COL in METRICS:\n","\n","    title=f\"{METRIC_COL} by Model\"\n","    out_file=METRIC_COL.lower().replace(\" \",\"_\")+\"_by_model.png\"\n","\n","    y_true=[df[(df.Model==m)&(df.Run==\"True\")][METRIC_COL].values[0] for m in models]\n","    y_ch=[df[(df.Model==m)&(df.Run==\"Chance\")][METRIC_COL].values[0] for m in models]\n","\n","    fig=go.Figure()\n","\n","    fig.add_bar(\n","        x=models,y=y_true,offsetgroup=\"true\",\n","        marker_color=[model_colors[m] for m in models],\n","        name=\"True labels\"\n","    )\n","\n","    fig.add_bar(\n","        x=models,y=y_ch,offsetgroup=\"shuffled\",\n","        marker_color=[hex_to_rgba(model_colors[m],0.35) for m in models],\n","        name=\"Shuffled labels\"\n","    )\n","\n","    fig.update_layout(\n","        barmode=\"group\",\n","        title=title,\n","        yaxis_title=METRIC_COL,\n","        xaxis_title=\"Model\",\n","        legend_title=\"\",\n","        width=1500,\n","        height=700\n","    )\n","\n","    fig.show()\n","    #fig.write_image(f\"{OUT_DIR}/{out_file}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_NbH45-bwiTp"},"outputs":[],"source":["import plotly.graph_objects as go\n","import plotly.express as px\n","\n","METRICS = [\"Accuracy\", \"Balanced Accuracy\", \"Macro F1\"]\n","\n","# ---------- auto models ----------\n","models = sorted(df[\"Model\"].unique())\n","\n","# ---------- auto colors ----------\n","palette = px.colors.qualitative.Plotly\n","model_colors = {m: palette[i % len(palette)] for i, m in enumerate(models)}\n","\n","def hex_to_rgba(hex_color, alpha):\n","    h = hex_color.lstrip(\"#\")\n","    r, g, b = (int(h[i:i+2], 16) for i in (0, 2, 4))\n","    return f\"rgba({r},{g},{b},{alpha})\"\n","\n","for METRIC_COL in METRICS:\n","\n","    title = f\"{METRIC_COL} by Model\"\n","    out_file = METRIC_COL.lower().replace(\" \", \"_\") + \"_by_model.svg\"\n","\n","    y_true = [df[(df.Model == m) & (df.Run == \"True\")][METRIC_COL].values[0] for m in models]\n","    y_ch = [df[(df.Model == m) & (df.Run == \"Chance\")][METRIC_COL].values[0] for m in models]\n","\n","    fig = go.Figure()\n","\n","    fig.add_bar(\n","        x=models, y=y_true, offsetgroup=\"true\",\n","        marker_color=[model_colors[m] for m in models],\n","        name=\"True labels\"\n","    )\n","\n","    fig.add_bar(\n","        x=models, y=y_ch, offsetgroup=\"shuffled\",\n","        marker_color=[hex_to_rgba(model_colors[m], 0.35) for m in models],\n","        name=\"Shuffled labels\"\n","    )\n","\n","    fig.update_layout(\n","        barmode=\"group\",\n","        title={\n","            'text': title,\n","            'font': {'size': 32}  # Larger title\n","        },\n","        yaxis_title=METRIC_COL,\n","        xaxis_title=\"Model\",\n","        legend_title=\"\",\n","        width=1500,\n","        height=700,\n","        # Increased font sizes for all text elements\n","        font=dict(size=18),  # Base font size for all text\n","        xaxis=dict(\n","            tickfont=dict(size=16),\n","            title=dict(font=dict(size=20))  # Correct syntax for axis title font\n","        ),\n","        yaxis=dict(\n","            tickfont=dict(size=16),\n","            title=dict(font=dict(size=20))  # Correct syntax for axis title font\n","        ),\n","        legend=dict(\n","            font=dict(size=16)\n","        )\n","    )\n","\n","    fig.show()\n","\n","    # Save as SVG for perfect scalability in Word\n","    # fig.write_image(\n","    #     f\"{OUT_DIR}/{out_file}\",\n","    #     format=\"svg\",\n","    #     width=1500,\n","    #     height=700\n","    # )"]},{"cell_type":"markdown","metadata":{"id":"Y45m-3v-wiTp"},"source":["# Appendix\n","\n","#### In case images do not render, I have displayed them below"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true,"id":"PESshJJWwiTp"},"outputs":[],"source":[]},{"cell_type":"code","source":[],"metadata":{"id":"67pyfnEmz3Dy"},"execution_count":null,"outputs":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":9193245,"sourceId":14394719,"sourceType":"datasetVersion"},{"datasetId":9196530,"sourceId":14399721,"sourceType":"datasetVersion"}],"dockerImageVersionId":31234,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"ADA_HW","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}